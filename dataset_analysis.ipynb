{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from dataset_analysis import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_generator(dataset_root_dir, dataset_split_list):\n",
    "    \"\"\"\n",
    "    A generator that yields the path of the annotation file, the path of the RGB folder and the path of the thermal folder.\n",
    "    :param dataset_root_dir:\n",
    "    :param dataset_split_list: e.g. [0,1,2,3,...]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rgb_top_dir = os.path.join(dataset_root_dir, 'sequences', 'RGB')\n",
    "    thermal_top_dir = os.path.join(dataset_root_dir, 'sequences', 'Thermal')\n",
    "    annot_top_dir = os.path.join(dataset_root_dir, 'annotations')\n",
    "\n",
    "    dataset_split_list_iter = tqdm(dataset_split_list, leave=False)\n",
    "    dataset_split_list_iter.set_description('progress: ')\n",
    "    for idx in dataset_split_list_iter:\n",
    "        idx = int(idx)\n",
    "        annot_path = os.path.join(annot_top_dir, f'{idx}.xml')\n",
    "        rgb_dir = os.path.join(rgb_top_dir, f'{idx}')\n",
    "        thermal_dir = os.path.join(thermal_top_dir, f'{idx}')\n",
    "\n",
    "        yield idx, annot_path, rgb_dir, thermal_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_dict_generator(dataset_root_dir, dataset_split_list):\n",
    "    for idx, annot_path, _, _ in path_generator(dataset_root_dir, dataset_split_list):\n",
    "        _xml_dict = parse_single_annotation_file(annot_path)\n",
    "        yield idx, _xml_dict, annot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_split_list(split_path):\n",
    "    with open(split_path,'r') as f:\n",
    "        split_list = f.readlines()\n",
    "        # convert to int\n",
    "        split_list = [int(x.strip()) for x in split_list]\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = './DATASET_ROOT'\n",
    "\n",
    "total_video_sequences = count_sequences(dataset_root_dir)\n",
    "total_frames = 0\n",
    "\n",
    "total_category_distribution_frame_level_dict = {}\n",
    "\n",
    "total_sequence_length_distribution = {}\n",
    "\n",
    "total_outside_distribution_frame_level_dict = {}\n",
    "total_occlusion_distribution_frame_level_dict = {}\n",
    "total_altitude_distribution_frame_level_dict = {}\n",
    "total_illumination_distribution_frame_level_dict = {}\n",
    "# total_keep_out_distribution_frame_level_dict = {}\n",
    "# total_cam_movement_distribution_frame_level_dict = {}\n",
    "total_scene_distribution_frame_level_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split_list = get_dataset_split_list(os.path.join(dataset_root_dir,'all.txt'))\n",
    "for idx, xml_dict, xml_path in annot_dict_generator(dataset_root_dir, dataset_split_list):\n",
    "    # if count >= 30:\n",
    "    #     break # for debug only\n",
    "    try:\n",
    "        # frames number update---------------------------------------------------------------------------------\n",
    "        frames = count_frames_per_sequence(xml_dict)\n",
    "        total_frames += frames\n",
    "        total_sequence_length_distribution[f'{idx}'] = frames\n",
    "        # frame-level category distribution--------------------------------------------------------------------\n",
    "        category_count_frame_level_dict = count_category_occurrences_frame_level_per_sequence(xml_dict)\n",
    "        total_category_distribution_frame_level_dict = merge_dicts(\n",
    "            total_category_distribution_frame_level_dict,\n",
    "            category_count_frame_level_dict\n",
    "        )\n",
    "        # frame-level attribute distribution--------------------------------------------------------------------\n",
    "        outside_distribution_frame_level_dict, occlusion_distribution_frame_level_dict, altitude_distribution_frame_level_dict, illumination_distribution_frame_level_dict, scene_distribution_frame_level_dict = count_attribute_occurrence_frame_level_per_sequence(\n",
    "            xml_dict)\n",
    "    except Exception as e:\n",
    "        print(\"\\033[1;31merror\\033[0m\")  # print bold \"error\" in red\n",
    "        traceback.print_exc()\n",
    "        print(f\"xml file:{xml_path}\")\n",
    "\n",
    "    total_outside_distribution_frame_level_dict = merge_dicts(total_outside_distribution_frame_level_dict,\n",
    "                                                              outside_distribution_frame_level_dict)\n",
    "    total_occlusion_distribution_frame_level_dict = merge_dicts(total_occlusion_distribution_frame_level_dict,\n",
    "                                                                occlusion_distribution_frame_level_dict)\n",
    "    total_altitude_distribution_frame_level_dict = merge_dicts(total_altitude_distribution_frame_level_dict,\n",
    "                                                               altitude_distribution_frame_level_dict)\n",
    "    total_illumination_distribution_frame_level_dict = merge_dicts(total_illumination_distribution_frame_level_dict,\n",
    "                                                                   illumination_distribution_frame_level_dict)\n",
    "    total_scene_distribution_frame_level_dict = merge_dicts(total_scene_distribution_frame_level_dict,\n",
    "                                                            scene_distribution_frame_level_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_video_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sequence_length_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_category_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_altitude_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_illumination_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_occlusion_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_outside_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scene_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_error_files(dataset_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bar_chart(total_sequence_length_distribution, title=\"Sequence Length Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bar_chart(dict(sorted(total_sequence_length_distribution.items(),key=lambda x:x[1])), title=\"Sequence Length Distribution Sorted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(total_category_distribution_frame_level_dict, title=\"Frame-level Category Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(total_scene_distribution_frame_level_dict, title=\"Frame-level Scene Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(total_altitude_distribution_frame_level_dict, title=\"Frame-level Altitudes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(total_occlusion_distribution_frame_level_dict, title=\"Frame-level Occlusions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(total_outside_distribution_frame_level_dict, title=\"Frame-level Outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dataset_split_list('D:\\\\Project_repository\\\\RGBT_multi_dataset\\\\DATASET_ROOT\\\\test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('D:\\\\Project_repository\\\\RGBT_multi_dataset\\\\DATASET_ROOT\\\\all.txt','w') as f:\n",
    "#     for i in range(120):\n",
    "#         f.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sequence_info_dict_list = []  # {\"idx\": int, \"frames\": int, \"categories\": Dict, \"altitude\": str}\n",
    "\n",
    "for idx, xml_dict, xml_path in annot_dict_generator(dataset_root_dir, dataset_split_list):\n",
    "    sequence_info_dict = {\n",
    "        \"idx\": idx,\n",
    "        \"frames\": count_frames_per_sequence(xml_dict),\n",
    "        \"categories\": count_category_occurrences_frame_level_per_sequence(xml_dict),\n",
    "        \"altitude\": {'30m': 0, '60m': 0, '90m': 0, '120m': 0}\n",
    "    }\n",
    "    sequence_info_dict['altitude'][xml_dict['altitude']] = sequence_info_dict['frames']\n",
    "    sequence_info_dict_list.append(sequence_info_dict)\n",
    "\n",
    "for i, sequence_info_dict in enumerate(sequence_info_dict_list):\n",
    "    assert sequence_info_dict['idx'] == i"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "train_prop = 0.6\n",
    "val_prop = 0.1\n",
    "test_prop = 0.3\n",
    "\n",
    "train_frames_tg = int(total_frames * train_prop + 0.5)  # target train frames\n",
    "val_frames_tg = int(total_frames * val_prop + 0.5)  # target val frames\n",
    "test_frames_tg = int(total_frames * test_prop + 0.5)  # target test frames\n",
    "\n",
    "category_proportion = {}\n",
    "for category in total_category_distribution_frame_level_dict:\n",
    "    category_proportion[category] = total_category_distribution_frame_level_dict[category] / total_frames\n",
    "\n",
    "altitudes_proportion = {}\n",
    "for altitude in total_altitude_distribution_frame_level_dict:\n",
    "    altitudes_proportion[altitude] = total_altitude_distribution_frame_level_dict[altitude] / total_frames\n",
    "\n",
    "tolerance = 0.1  # tolerance\n",
    "\n",
    "# the target number of frames for each altitude\n",
    "train_altitude_count_tg = {}\n",
    "for altitude in altitudes_proportion:\n",
    "    train_altitude_count_tg[altitude] = int(train_frames_tg * altitudes_proportion[altitude] + 0.5)\n",
    "val_altitude_count_tg = {}\n",
    "for altitude in altitudes_proportion:\n",
    "    val_altitude_count_tg[altitude] = int(val_frames_tg * altitudes_proportion[altitude] + 0.5)\n",
    "test_altitude_count_tg = {}\n",
    "for altitude in altitudes_proportion:\n",
    "    test_altitude_count_tg[altitude] = int(test_frames_tg * altitudes_proportion[altitude] + 0.5)\n",
    "\n",
    "# the target number of counts for each category\n",
    "total_category_count = 0\n",
    "for category in total_category_distribution_frame_level_dict:\n",
    "    total_category_count += total_category_distribution_frame_level_dict[category]\n",
    "category_proportion = {}\n",
    "for category in total_category_distribution_frame_level_dict:\n",
    "    category_proportion[category] = total_category_distribution_frame_level_dict[category] / total_category_count\n",
    "\n",
    "train_category_count_tg = {}\n",
    "for category in category_proportion:\n",
    "    [category] = int(train_prop * total_category_distribution_frame_level_dict[category] + 0.5)\n",
    "val_category_count_tg = {}\n",
    "for category in category_proportion:\n",
    "    val_category_count_tg[category] = int(val_prop * total_category_distribution_frame_level_dict[category] + 0.5)\n",
    "test_category_count_tg = {}\n",
    "for category in category_proportion:\n",
    "    test_category_count_tg[category] = int(test_prop * total_category_distribution_frame_level_dict[category] + 0.5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "sorted_sequences_dict = dict(sorted(total_sequence_length_distribution.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "sorted_sequences_idx_list = list(sorted_sequences_dict.keys())  # iterate from longest to shortest\n",
    "frames_len_list = list(sorted_sequences_dict.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# node structure: (['train'|'val'|'test', ...],\n",
    "# (train frames, ...)\n",
    "# (train_category_count_dict,val_category_count_dict, test_category_count_dict),\n",
    "# (altitude_count_dict))\n",
    "\n",
    "def heuristic(node, tolerance, train_tg, val_tg, test_tg):\n",
    "    \"\"\"\n",
    "    the heuristic function for A* search, the lower, the better\n",
    "    \"\"\"\n",
    "    train_frames_tg, train_category_count_tg, train_altitude_count_tg = train_tg\n",
    "    val_frames_tg, val_category_count_tg, val_altitude_count_tg = val_tg\n",
    "    test_frames_tg, test_category_count_tg, test_altitude_count_tg = test_tg\n",
    "\n",
    "    node_train_frames, node_val_frames, node_test_frames = node[1]\n",
    "    node_train_category_count, node_val_category_count, node_test_category_count = node[2]\n",
    "    node_train_altitude_count, node_val_altitude_count, node_test_altitude_count = node[3]\n",
    "\n",
    "    # if frames are too much, return inf\n",
    "    if node_train_frames > train_frames_tg * (1 + tolerance) or node_val_frames > val_frames_tg * (1 + tolerance) \\\n",
    "            or node_test_frames > test_frames_tg * (1 + tolerance):\n",
    "        return float('inf')\n",
    "\n",
    "    # if category counts exceed target too much, return inf\n",
    "    if node_train_category_count > train_category_count_tg * (1 + tolerance) or \\\n",
    "            node_val_category_count > val_category_count_tg * (1 + tolerance) or \\\n",
    "            node_test_category_count > test_category_count_tg * (1 + tolerance):\n",
    "        return float('inf')\n",
    "\n",
    "    # if altitude counts exceed target too much, return inf\n",
    "    if node_train_altitude_count > train_altitude_count_tg * (1 + tolerance) or \\\n",
    "            node_val_altitude_count > val_altitude_count_tg * (1 + tolerance) or \\\n",
    "            node_test_altitude_count > test_altitude_count_tg * (1 + tolerance):\n",
    "        return float('inf')\n",
    "\n",
    "    # heuristic\n",
    "    frames_prop_score = abs(node_train_frames / train_frames_tg - 1) + \\\n",
    "                        abs(node_val_frames / val_frames_tg - 1) + \\\n",
    "                        abs(node_test_frames / test_frames_tg - 1)\n",
    "    category_prop_score = abs(node_train_category_count / train_category_count_tg - 1) + \\\n",
    "                          abs(node_val_category_count / val_category_count_tg - 1) + \\\n",
    "                          abs(node_test_category_count / test_category_count_tg - 1)\n",
    "    altitude_prop_score = abs(node_train_altitude_count / train_altitude_count_tg - 1) + \\\n",
    "                          abs(node_val_altitude_count / val_altitude_count_tg - 1) + \\\n",
    "                          abs(node_test_altitude_count / test_altitude_count_tg - 1)\n",
    "\n",
    "    return frames_prop_score + category_prop_score + altitude_prop_score\n",
    "\n",
    "\n",
    "# iter order: val, test, train\n",
    "priority_queue = PriorityQueue()\n",
    "\n",
    "# first node is val\n",
    "first_node = (['val'], (0, sequence_info_dict_list[sorted_sequences_idx_list[0]]['frames'], 0),  # frames count\n",
    "              ({'person': 0, 'cycle': 0, 'car': 0},  # train_category_count_dict\n",
    "               sequence_info_dict_list[sorted_sequences_idx_list[0]]['categories'],  # val_category_count_dict\n",
    "               {'person': 0, 'cycle': 0, 'car': 0},),  # test_category_count_dict\n",
    "              ({'30m': 0, '60m': 0, '90m': 0, '120m': 0},  # train altitude_count_dict\n",
    "               sequence_info_dict_list[sorted_sequences_idx_list[0]]['altitude'],  # val altitude_count_dict\n",
    "               {'30m': 0, '60m': 0, '90m': 0, '120m': 0}))  # test altitude_count_dict\n",
    "\n",
    "priority_queue.put(\n",
    "    (heuristic(first_node, tolerance, (train_frames_tg, train_category_count_tg, train_altitude_count_tg),\n",
    "               (val_frames_tg, val_category_count_tg, val_altitude_count_tg),\n",
    "               (test_frames_tg, test_category_count_tg, test_altitude_count_tg)), first_node))\n",
    "\n",
    "# A* search\n",
    "while not priority_queue.empty():\n",
    "    current_node = priority_queue.get()[1]\n",
    "    current_split_list = current_node[0]  # ['train'|'val'|'test', ...]\n",
    "    current_node_train_frames, current_node_val_frames, current_node_test_frames = current_node[1]\n",
    "    current_node_train_category_count, current_node_val_category_count, current_node_test_category_count = current_node[2]\n",
    "    current_node_train_altitude_count, current_node_val_altitude_count, current_node_test_altitude_count = current_node[3]\n",
    "\n",
    "    # if current node is the last one, break\n",
    "    if len(current_node[0]) == len(sorted_sequences_idx_list):\n",
    "        break\n",
    "\n",
    "    # if current node is not the last one, add next node to priority queue\n",
    "    next_node_idx = len(current_node[0])\n",
    "\n",
    "    next_node = (current_split_list + ['val'],\n",
    "                 (current_node_train_frames, current_node_val_frames + frames_len_list[next_node_idx],\n",
    "                  current_node_test_frames),\n",
    "                 (current_node_train_category_count,\n",
    "                  current_node_val_category_count + sequence_info_dict_list[sorted_sequences_idx_list[next_node_idx]][\n",
    "                      'categories'], current_node_test_category_count),\n",
    "                 (current_node_train_altitude_count,\n",
    "                  current_node_val_altitude_count + sequence_info_dict_list[sorted_sequences_idx_list[next_node_idx]][\n",
    "                      'altitude'], current_node_test_altitude_count))\n",
    "\n",
    "    priority_queue.put(\n",
    "        (heuristic(next_node, tolerance, (train_frames_tg, train_category_count_tg, train_altitude_count_tg),\n",
    "                   (val_frames_tg, val_category_count_tg, val_altitude_count_tg),\n",
    "                   (test_frames_tg, test_category_count_tg, test_altitude_count_tg)), next_node))\n",
    "\n",
    "    next_node = (current_split_list + ['test'],\n",
    "                 (current_node_train_frames, current_node_val_frames,\n",
    "                  current_node_test_frames + frames_len_list[next_node_idx]),\n",
    "                 (current_node_train_category_count, current_node_val_category_count,\n",
    "                  current_node_test_category_count + sequence_info_dict_list[sorted_sequences_idx_list[next_node_idx]][\n",
    "                      'categories']),\n",
    "                 (current_node_train_altitude_count, current_node_val_altitude_count,\n",
    "                  current_node_test_altitude_count + sequence_info_dict_list[sorted_sequences_idx_list[next_node_idx]][\n",
    "                      'altitude']))\n",
    "\n",
    "    priority_queue.put(\n",
    "        (heuristic(next_node, tolerance, (train_frames_tg, train_category_count_tg, train_altitude_count_tg),\n",
    "                   (val_frames_tg, val_category_count_tg, val_altitude_count_tg),\n",
    "                   (test_frames_tg, test_category_count_tg, test_altitude_count_tg)), next_node))\n",
    "\n",
    "    next_node = (current_split_list + ['train'],\n",
    "                 (current_node_train_frames + frames_len_list[next_node_idx], current_node_val_frames,\n",
    "                  current_node_test_frames),\n",
    "                 (current_node_train_category_count + sequence_info_dict_list[sorted_sequences_idx_list[next_node_idx]][\n",
    "                     'categories'], current_node_val_category_count, current_node_test_category_count),\n",
    "                 (current_node_train_altitude_count + sequence_info_dict_list[sorted_sequences_idx_list[next_node_idx]][\n",
    "                     'altitude'], current_node_val_altitude_count, current_node_test_altitude_count))\n",
    "\n",
    "    priority_queue.put(\n",
    "        (heuristic(next_node, tolerance, (train_frames_tg, train_category_count_tg, train_altitude_count_tg),\n",
    "                     (val_frames_tg, val_category_count_tg, val_altitude_count_tg),\n",
    "                        (test_frames_tg, test_category_count_tg, test_altitude_count_tg)), next_node))\n",
    "\n",
    "    print(f'{len(current_split_list)} / 120')\n",
    "\n",
    "# print result\n",
    "print(current_node)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(1)\n",
    "#\n",
    "# def random_dic(dicts):\n",
    "#     dict_key_ls = list(dicts.keys())\n",
    "#     random.shuffle(dict_key_ls)\n",
    "#     new_dic = {}\n",
    "#     for key in dict_key_ls:\n",
    "#         new_dic[key] = dicts.get(key)\n",
    "#     return new_dic\n",
    "#\n",
    "# # shuffled_thermal_len_dict = dict(sorted(total_sequence_length_distribution.items(),key=lambda x:x[1]))\n",
    "# shuffled_thermal_len_dict = random_dic(total_sequence_length_distribution)  # shuffled, don't use sorted\n",
    "# # count total\n",
    "# total = 0\n",
    "# for key, val in shuffled_thermal_len_dict.items():\n",
    "#     total += val\n",
    "#\n",
    "# # proportionï¼Œ 12:6:1\n",
    "# train_num = int(total * 0.632 + 0.5)\n",
    "# val_num = int(total * 0.316 + 0.5)\n",
    "# test_num = total - train_num - val_num\n",
    "#\n",
    "# train_list = []\n",
    "# val_list = []\n",
    "# test_list = []\n",
    "# for key, val in shuffled_thermal_len_dict.items():\n",
    "#     if train_num > 0 and train_num - val >= 0:  # if training set is not full\n",
    "#         train_list.append(f'{key}\\n')\n",
    "#         train_num -= val\n",
    "#     elif val_num > 0 and val_num - val >= 0:  # val\n",
    "#         val_list.append(f'{key}\\n')\n",
    "#         val_num -= val\n",
    "#     else:  # test\n",
    "#         test_list.append(f'{key}\\n')\n",
    "#\n",
    "# train_txt_path = os.path.join(dataset_root_dir,'train.txt')\n",
    "# val_txt_path = os.path.join(dataset_root_dir,'val.txt')\n",
    "# test_txt_path = os.path.join(dataset_root_dir,'test.txt')\n",
    "#\n",
    "# with open(train_txt_path, 'w') as f:\n",
    "#     f.writelines(train_list)\n",
    "# with open(val_txt_path, 'w') as f:\n",
    "#     f.writelines(val_list)\n",
    "# with open(test_txt_path, 'w') as f:\n",
    "#     f.writelines(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_sequences = 0\n",
    "train_frames = 0\n",
    "\n",
    "train_category_distribution_frame_level_dict = {}\n",
    "\n",
    "train_sequence_length_distribution = {}\n",
    "\n",
    "train_outside_distribution_frame_level_dict = {}\n",
    "train_occlusion_distribution_frame_level_dict = {}\n",
    "train_altitude_distribution_frame_level_dict = {}\n",
    "train_illumination_distribution_frame_level_dict = {}\n",
    "train_scene_distribution_frame_level_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split_list = get_dataset_split_list(os.path.join(dataset_root_dir,'train.txt'))\n",
    "for idx, xml_dict, xml_path in annot_dict_generator(dataset_root_dir, dataset_split_list):\n",
    "    # if count >= 30:\n",
    "    #     break # for debug only\n",
    "    try:\n",
    "        # frames number update---------------------------------------------------------------------------------\n",
    "        train_video_sequences += 1\n",
    "        frames = count_frames_per_sequence(xml_dict)\n",
    "        train_frames += frames\n",
    "        train_sequence_length_distribution[f'{idx}'] = frames\n",
    "        # frame-level category distribution--------------------------------------------------------------------\n",
    "        category_count_frame_level_dict = count_category_occurrences_frame_level_per_sequence(xml_dict)\n",
    "        train_category_distribution_frame_level_dict = merge_dicts(\n",
    "            train_category_distribution_frame_level_dict,\n",
    "            category_count_frame_level_dict\n",
    "        )\n",
    "        # frame-level attribute distribution--------------------------------------------------------------------\n",
    "        outside_distribution_frame_level_dict, occlusion_distribution_frame_level_dict, altitude_distribution_frame_level_dict, illumination_distribution_frame_level_dict, scene_distribution_frame_level_dict = count_attribute_occurrence_frame_level_per_sequence(\n",
    "            xml_dict)\n",
    "    except Exception as e:\n",
    "        print(\"\\033[1;31merror\\033[0m\")  # print bold \"error\" in red\n",
    "        traceback.print_exc()\n",
    "        print(f\"xml file:{xml_path}\")\n",
    "\n",
    "    train_outside_distribution_frame_level_dict = merge_dicts(train_outside_distribution_frame_level_dict,\n",
    "                                                              outside_distribution_frame_level_dict)\n",
    "    train_occlusion_distribution_frame_level_dict = merge_dicts(train_occlusion_distribution_frame_level_dict,\n",
    "                                                                occlusion_distribution_frame_level_dict)\n",
    "    train_altitude_distribution_frame_level_dict = merge_dicts(train_altitude_distribution_frame_level_dict,\n",
    "                                                               altitude_distribution_frame_level_dict)\n",
    "    train_illumination_distribution_frame_level_dict = merge_dicts(train_illumination_distribution_frame_level_dict,\n",
    "                                                                   illumination_distribution_frame_level_dict)\n",
    "    train_scene_distribution_frame_level_dict = merge_dicts(train_scene_distribution_frame_level_dict,\n",
    "                                                            scene_distribution_frame_level_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence_length_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_altitude_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_illumination_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_occlusion_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outside_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scene_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bar_chart(train_sequence_length_distribution, title=\"Sequence Length Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(train_category_distribution_frame_level_dict, title=\"Frame-level Category Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(train_scene_distribution_frame_level_dict, title=\"Frame-level Scene Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(train_altitude_distribution_frame_level_dict, title=\"Frame-level Altitudes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(train_occlusion_distribution_frame_level_dict, title=\"Frame-level Occlusions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(train_outside_distribution_frame_level_dict, title=\"Frame-level Outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_video_sequences = 0\n",
    "val_frames = 0\n",
    "\n",
    "val_category_distribution_frame_level_dict = {}\n",
    "\n",
    "val_sequence_length_distribution = {}\n",
    "\n",
    "val_outside_distribution_frame_level_dict = {}\n",
    "val_occlusion_distribution_frame_level_dict = {}\n",
    "val_altitude_distribution_frame_level_dict = {}\n",
    "val_illumination_distribution_frame_level_dict = {}\n",
    "val_scene_distribution_frame_level_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split_list = get_dataset_split_list(os.path.join(dataset_root_dir,'val.txt'))\n",
    "for idx, xml_dict, xml_path in annot_dict_generator(dataset_root_dir, dataset_split_list):\n",
    "    # if count >= 30:\n",
    "    #     break # for debug only\n",
    "    try:\n",
    "        # frames number update---------------------------------------------------------------------------------\n",
    "        val_video_sequences += 1\n",
    "        frames = count_frames_per_sequence(xml_dict)\n",
    "        val_frames += frames\n",
    "        val_sequence_length_distribution[f'{idx}'] = frames\n",
    "        # frame-level category distribution--------------------------------------------------------------------\n",
    "        category_count_frame_level_dict = count_category_occurrences_frame_level_per_sequence(xml_dict)\n",
    "        val_category_distribution_frame_level_dict = merge_dicts(\n",
    "            val_category_distribution_frame_level_dict,\n",
    "            category_count_frame_level_dict\n",
    "        )\n",
    "        # frame-level attribute distribution--------------------------------------------------------------------\n",
    "        outside_distribution_frame_level_dict, occlusion_distribution_frame_level_dict, altitude_distribution_frame_level_dict, illumination_distribution_frame_level_dict, scene_distribution_frame_level_dict = count_attribute_occurrence_frame_level_per_sequence(\n",
    "            xml_dict)\n",
    "    except Exception as e:\n",
    "        print(\"\\033[1;31merror\\033[0m\")  # print bold \"error\" in red\n",
    "        traceback.print_exc()\n",
    "        print(f\"xml file:{xml_path}\")\n",
    "\n",
    "    val_outside_distribution_frame_level_dict = merge_dicts(val_outside_distribution_frame_level_dict,\n",
    "                                                              outside_distribution_frame_level_dict)\n",
    "    val_occlusion_distribution_frame_level_dict = merge_dicts(val_occlusion_distribution_frame_level_dict,\n",
    "                                                                occlusion_distribution_frame_level_dict)\n",
    "    val_altitude_distribution_frame_level_dict = merge_dicts(val_altitude_distribution_frame_level_dict,\n",
    "                                                               altitude_distribution_frame_level_dict)\n",
    "    val_illumination_distribution_frame_level_dict = merge_dicts(val_illumination_distribution_frame_level_dict,\n",
    "                                                                   illumination_distribution_frame_level_dict)\n",
    "    val_scene_distribution_frame_level_dict = merge_dicts(val_scene_distribution_frame_level_dict,\n",
    "                                                            scene_distribution_frame_level_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_video_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence_length_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_category_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_altitude_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_illumination_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_occlusion_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outside_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scene_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bar_chart(val_sequence_length_distribution, title=\"Sequence Length Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(val_category_distribution_frame_level_dict, title=\"Frame-level Category Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(val_scene_distribution_frame_level_dict, title=\"Frame-level Scene Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(val_altitude_distribution_frame_level_dict, title=\"Frame-level Altitudes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(val_occlusion_distribution_frame_level_dict, title=\"Frame-level Occlusions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(val_outside_distribution_frame_level_dict, title=\"Frame-level Outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_sequences = 0\n",
    "test_frames = 0\n",
    "\n",
    "test_category_distribution_frame_level_dict = {}\n",
    "\n",
    "test_sequence_length_distribution = {}\n",
    "\n",
    "test_outside_distribution_frame_level_dict = {}\n",
    "test_occlusion_distribution_frame_level_dict = {}\n",
    "test_altitude_distribution_frame_level_dict = {}\n",
    "test_illumination_distribution_frame_level_dict = {}\n",
    "test_scene_distribution_frame_level_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split_list = get_dataset_split_list(os.path.join(dataset_root_dir,'test.txt'))\n",
    "for idx, xml_dict, xml_path in annot_dict_generator(dataset_root_dir, dataset_split_list):\n",
    "    # if count >= 30:\n",
    "    #     break # for debug only\n",
    "    try:\n",
    "        # frames number update---------------------------------------------------------------------------------\n",
    "        test_video_sequences += 1\n",
    "        frames = count_frames_per_sequence(xml_dict)\n",
    "        test_frames += frames\n",
    "        test_sequence_length_distribution[f'{idx}'] = frames\n",
    "        # frame-level category distribution--------------------------------------------------------------------\n",
    "        category_count_frame_level_dict = count_category_occurrences_frame_level_per_sequence(xml_dict)\n",
    "        test_category_distribution_frame_level_dict = merge_dicts(\n",
    "            test_category_distribution_frame_level_dict,\n",
    "            category_count_frame_level_dict\n",
    "        )\n",
    "        # frame-level attribute distribution--------------------------------------------------------------------\n",
    "        outside_distribution_frame_level_dict, occlusion_distribution_frame_level_dict, altitude_distribution_frame_level_dict, illumination_distribution_frame_level_dict, scene_distribution_frame_level_dict = count_attribute_occurrence_frame_level_per_sequence(\n",
    "            xml_dict)\n",
    "    except Exception as e:\n",
    "        print(\"\\033[1;31merror\\033[0m\")  # print bold \"error\" in red\n",
    "        traceback.print_exc()\n",
    "        print(f\"xml file:{xml_path}\")\n",
    "\n",
    "    test_outside_distribution_frame_level_dict = merge_dicts(test_outside_distribution_frame_level_dict,\n",
    "                                                              outside_distribution_frame_level_dict)\n",
    "    test_occlusion_distribution_frame_level_dict = merge_dicts(test_occlusion_distribution_frame_level_dict,\n",
    "                                                                occlusion_distribution_frame_level_dict)\n",
    "    test_altitude_distribution_frame_level_dict = merge_dicts(test_altitude_distribution_frame_level_dict,\n",
    "                                                               altitude_distribution_frame_level_dict)\n",
    "    test_illumination_distribution_frame_level_dict = merge_dicts(test_illumination_distribution_frame_level_dict,\n",
    "                                                                   illumination_distribution_frame_level_dict)\n",
    "    test_scene_distribution_frame_level_dict = merge_dicts(test_scene_distribution_frame_level_dict,\n",
    "                                                            scene_distribution_frame_level_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence_length_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_category_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_altitude_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_illumination_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_occlusion_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outside_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene_distribution_frame_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bar_chart(test_sequence_length_distribution, title=\"Sequence Length Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(test_category_distribution_frame_level_dict, title=\"Frame-level Category Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(test_scene_distribution_frame_level_dict, title=\"Frame-level Scene Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(test_altitude_distribution_frame_level_dict, title=\"Frame-level Altitudes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(test_occlusion_distribution_frame_level_dict, title=\"Frame-level Occlusions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(test_outside_distribution_frame_level_dict, title=\"Frame-level Outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_ratio_dict = {'train': train_frames, 'val': val_frames, 'test': test_frames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_ratio_dict = {'train': train_video_sequences, 'val': val_video_sequences, 'test': test_video_sequences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(frames_ratio_dict, 'Frames Proportion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pie_chart(sequences_ratio_dict, 'Sequences Proportion')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
